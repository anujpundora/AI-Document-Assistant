# ğŸ“„ AI Document Assistant (RAG-based)

An AI-powered Document Assistant that allows users to upload PDFs and interact with them using natural language queries.

The system uses **Retrieval-Augmented Generation (RAG)** to enable semantic search, contextual question answering, and document summarization using modern AI workflows.

---

## ğŸš€ Project Overview

Traditional document search relies on keyword matching.

This project enables **semantic understanding** of documents by converting text into vector embeddings and retrieving relevant information before generating answers using an LLM.

Users can:

âœ… Ask questions about a PDF  
âœ… Generate document summaries  
âœ… Perform semantic search  
âœ… Get context-aware AI responses  

---

## ğŸ§  What is RAG?

**Retrieval-Augmented Generation (RAG)** combines:

1. **Retrieval System**
   - Finds relevant information from documents.

2. **Generation Model (LLM)**
   - Uses retrieved context to generate accurate responses.

### RAG Flow

![alt text](image.png)

Unlike normal LLM responses, answers are grounded in uploaded documents.

---

## ğŸ§© System Architecture

![alt text](image.png)

---

## âš™ï¸ Technologies Used

| Component | Technology |
|------------|------------|
| Language | Python |
| Framework | LangChain |
| LLM | Google Gemini API |
| Embeddings | HuggingFace Sentence Transformers |
| Vector Database | FAISS |
| PDF Parsing | PyPDFLoader |
| Environment Management | dotenv |

---

## ğŸ” Core Concepts Explained

---

### âœ… Embeddings

Embeddings convert text into numerical vectors representing **semantic meaning**.

---

## âš™ï¸ Technologies Used

| Component | Technology |
|------------|------------|
| Language | Python |
| Framework | LangChain |
| LLM | Google Gemini API |
| Embeddings | HuggingFace Sentence Transformers |
| Vector Database | FAISS |
| PDF Parsing | PyPDFLoader |
| Environment Management | dotenv |

---

## ğŸ” Core Concepts Explained

---

### âœ… Embeddings

Embeddings convert text into numerical vectors representing **semantic meaning**.

Similar meanings produce nearby vectors.

---

### âœ… Why Chunking?

LLMs and embedding models have token limits.

Large documents are split into smaller parts:
Overlap preserves contextual continuity.

---

### âœ… Vector Database (FAISS)

FAISS stores embeddings and enables fast similarity search.

Instead of keyword search:
"What is backend language?"

System retrieves semantically similar content like:

Python is used for backend development.


---

### âœ… Semantic Retrieval

User query â†’ embedding â†’ nearest vectors selected.

Only **top-k relevant chunks** are sent to Gemini.

This reduces:
- hallucinations
- token usage
- API cost

---

### âœ… Why Not Send Full PDF?

Sending entire documents:

âŒ exceeds token limits  
âŒ increases latency  
âŒ increases cost  

RAG retrieves only relevant knowledge.

---

## ğŸ“„ Features

- âœ… PDF-based Question Answering
- âœ… Semantic Document Search
- âœ… Intelligent Document Summarization
- âœ… Query Compression for long inputs
- âœ… API Rate Limit Handling
- âœ… Context-Grounded Responses
- âœ… Efficient Token Usage

---

## ğŸ—ï¸ Project Structure

![alt text](image.png)

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Clone Repository
python3 -m venv venv
source venv/bin/activate

---

### 3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

---

### 4ï¸âƒ£ Add Gemini API Key

Create `.env`

GOOGLE_API_KEY=your_api_key

---

### 5ï¸âƒ£ Create Vector Database

---

### 6ï¸âƒ£ Run Assistant

---

## ğŸ§  Interview Discussion Points

This project demonstrates:

- Retrieval-Augmented Generation (RAG)
- Semantic Search Systems
- Vector Databases
- Embedding Models
- LLM Integration
- Token Optimization
- API Rate Limit Handling
- AI System Design

---

## ğŸ‘¨â€ğŸ’» Author

Built as part of hands-on learning in **AI Engineering & Agentic Systems**.